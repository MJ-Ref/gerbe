# StageÂ 3 â€‘ SyntheticÂ Falsification Harness ðŸŽ¯

*Objective*  
Verify that Gerbeâ€™s obstruction detector is **accurate**:  
*high recall* (catches injected contradictions) and *low falseâ€‘positive* rate.

---

## 1Â Â·Â Folder layout

```
synthetic_harness/
â”œâ”€â”€ generate_cases.py     # builds labelled random graphs
â”œâ”€â”€ eval_precision.py     # runs detector, computes P/R/F1
â””â”€â”€ STAGE_3_GUIDE.md      # <â€‘â€‘ this file
```

(Weâ€™ll add the two scripts in PRâ€‘2 of this stage.)

---

## 2Â Â·Â Pass criteria

| Metric | Threshold |
|--------|-----------|
| **Recall** | â‰¥Â 0.95 |
| **Precision** | â‰¥Â 0.90 |
| **F1 score** | â‰¥Â 0.92 |

Measurements taken over **1Â 000 random graphs** with:

* 100â€“300 nodes  
* 64â€‘D embeddings  
* Average degreeÂ â‰ˆÂ 4  
* 1â€“5 injected embedding obstructions **and/or** policy obstructions per graph  
* Optional numeric noise that does **not** break consistency (to test FP rate).

---

## 3Â Â·Â Running the harness

```bash
cd synthetic_harness
python generate_cases.py --n-graphs 1000 --out dataset.pkl
python eval_precision.py  --in dataset.pkl
```

`eval_precision.py` prints:

```
Graphs tested: 1000
TrueÂ Obstructions:  4Â 999
Detected:          4Â 823
FalseÂ Positives:      387
Recall: 0.964  Precision: 0.926  F1: 0.944
```

Script exits **0** only if all three thresholds meet the table above.

---

## 4Â Â·Â Implementation hints

### 4.1 generate_cases.py

* Reuse `synthetic_graph()` from StageÂ 1 to build base graph.  
* Pick random triangles and **flip** one edgeâ€™s matrix (numeric) or JSON patch (policy) to create groundâ€‘truth obstruction.  
* Store:  
  * `mats`, `patches`, `base_vec`, `base_policy`, `truth set` (list of offending triangles).

### 4.2 eval_precision.py

* Loop over stored graphs.  
* Run the same `embedding_obstructions()` and `policy_obstructions()` functions.  
* Compare detector output to groundâ€‘truth sets â†’ TP / FP / FN.

### 4.3 speed target

Full 1Â 000â€‘graph eval should finish **<Â 3Â minutes** on laptop CPU.

---

## 5Â Â·Â Deliverables

* `dataset.pkl` â€“ serialized test graphs (ignored in git via `.gitattributes`)  
* `report.md` â€“ summary table & oneâ€‘liner â€œStageÂ 3 passed / failedâ€  
* (Optional) ROC curve PNG if you sweep tolerance parameters.

---

## 6Â Â·Â Troubleshooting tips

| Symptom | Likely cause | Fix |
|---------|--------------|-----|
| Recall low | Bug injection not actually detectable (missing edge in graph). | Ensure each injected triple has all three edges present. |
| Many false positives | Tolerance too strict; numeric noise triggers flags. | Relax default tol or set perâ€‘transform tol. |
| Runtime >Â 3Â min | Graphs too dense; use `avg_deg` 4â€‘6. | Reduce node count or parallelise over CPU cores. |

---

## 7Â Â·Â Stage exit

* **Green**: Precision, Recall, F1 â‰¥ thresholds â†’ move to StageÂ 4 (autoâ€‘graph generator).  
* **Red**: Identify which metric fails â†’ tweak tolerance, improve inverse fns, or adjust injection logic.

---
